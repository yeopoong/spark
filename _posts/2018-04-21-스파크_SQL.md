---
layout: post
title: "스파크 SQL"
categories: spark
description: "구조화된 데이터셋 처리하기"
---

## 스파크 SQL 이란? 

### 지원하는 데이터셋 
* JSON 형식 파일
* Parquet 형식 파일
* ORC 형식 파일
* JDBC를 지원하는 데이터베이
* 하이브 호환 테이블
* 스파크 SQL 전용 테이블

### hive-site.xml 

```xml
<configuration>
  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/home/vagrant/data</value>
  </property>
</configuration>
```

## DataFrame을 이용하여 데이터처리  

### 스파크 SQL 초기화
```
```

### RDD to DataFrame  

```scala
scala> case class Dessert(menuId: String, name: String, price: Int, kcal: Int)
```

```scala
scala> dessertRDD = sc.textFile("dessert-menu.csv") 
```

```scala
scala> dessertDF.printSchema 
```

### DataFrame to RDD

```scala
scala> val rowRDD = dessertDF.rdd 
```

### DataFrame SQL 

```
scala> dessertDF.registerTempTable("dessert_table") 
```

### DataFrame API 

### DataFrame UDF 

```scala
scala> val strlen = sqlContext.udf.register("strlen", (str: String) => str.length)
```

### JDBC를 통해 스파크 SQL 이용하기 

## 스파크 SQL 튜닝하기

### 테이블 캐시

### 파티션 수

### 브로드케스트 결합


## 참조
* http://scala-ide.org/blog/Xsource-compatibility.html
